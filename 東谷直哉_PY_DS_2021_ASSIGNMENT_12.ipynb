{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "東谷直哉 - PY-DS-2021-ASSIGNMENT-12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/higshitani/higshitani.github.io/blob/main/%E6%9D%B1%E8%B0%B7%E7%9B%B4%E5%93%89_PY_DS_2021_ASSIGNMENT_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "関数の学習の性能をアップ：\n",
        "*   中間層の素子数を調整する（現状では12）\n",
        "*   活性化関数の形を変えてみる（ 'sigmoid'の代わりに 'relu' を使う）\n",
        "*   学習回数を調整する(epochs=値, batch_size=値 の設定）\n",
        "*   評価関数を変えてみる（loss='mean_squared_error'の箇所）\n",
        "*   学習用データの数やデータの範囲を調整してみる\n",
        "*   中間層を増やしてみる（ディープニューラルネット化する）\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hSgVUb0g0qV9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yNOuRg-x0jPq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06e24629-93d7-44de-cba2-cb791827c692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1164 - val_loss: 0.0869\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.0635\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0455\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0294\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0174\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0105\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0064\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0039\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0026\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.5281e-04 - val_loss: 8.9728e-04\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.0452e-04 - val_loss: 7.8957e-04\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.1384e-04 - val_loss: 7.1253e-04\n",
            "Epoch 16/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.4769e-04 - val_loss: 6.6067e-04\n",
            "Epoch 17/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0682e-04 - val_loss: 6.2427e-04\n",
            "Epoch 18/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7793e-04 - val_loss: 5.9906e-04\n",
            "Epoch 19/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5922e-04 - val_loss: 5.8020e-04\n",
            "Epoch 20/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.4306e-04 - val_loss: 5.6845e-04\n",
            "Epoch 21/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 5.3150e-04 - val_loss: 5.5362e-04\n",
            "Epoch 22/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 5.2027e-04 - val_loss: 5.4163e-04\n",
            "Epoch 23/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 5.1242e-04 - val_loss: 5.3575e-04\n",
            "Epoch 24/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0242e-04 - val_loss: 5.2657e-04\n",
            "Epoch 25/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.9857e-04 - val_loss: 5.1806e-04\n",
            "Epoch 26/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9097e-04 - val_loss: 5.1442e-04\n",
            "Epoch 27/150\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.8157e-04 - val_loss: 5.0342e-04\n",
            "Epoch 28/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.7499e-04 - val_loss: 4.9840e-04\n",
            "Epoch 29/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.7086e-04 - val_loss: 4.9504e-04\n",
            "Epoch 30/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6605e-04 - val_loss: 4.9418e-04\n",
            "Epoch 31/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6294e-04 - val_loss: 4.9555e-04\n",
            "Epoch 32/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6251e-04 - val_loss: 4.8611e-04\n",
            "Epoch 33/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4990e-04 - val_loss: 4.7391e-04\n",
            "Epoch 34/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.4628e-04 - val_loss: 4.7065e-04\n",
            "Epoch 35/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.4256e-04 - val_loss: 4.7052e-04\n",
            "Epoch 36/150\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4359e-04 - val_loss: 4.6473e-04\n",
            "Epoch 37/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3815e-04 - val_loss: 4.6510e-04\n",
            "Epoch 38/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.3020e-04 - val_loss: 4.6396e-04\n",
            "Epoch 39/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3178e-04 - val_loss: 4.6215e-04\n",
            "Epoch 40/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2721e-04 - val_loss: 4.4895e-04\n",
            "Epoch 41/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3540e-04 - val_loss: 4.4891e-04\n",
            "Epoch 42/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.2514e-04 - val_loss: 4.4478e-04\n",
            "Epoch 43/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1699e-04 - val_loss: 4.4376e-04\n",
            "Epoch 44/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1604e-04 - val_loss: 4.8246e-04\n",
            "Epoch 45/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.2186e-04 - val_loss: 4.3702e-04\n",
            "Epoch 46/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1018e-04 - val_loss: 4.4182e-04\n",
            "Epoch 47/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.1213e-04 - val_loss: 4.4128e-04\n",
            "Epoch 48/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.0791e-04 - val_loss: 4.3687e-04\n",
            "Epoch 49/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.0483e-04 - val_loss: 4.3870e-04\n",
            "Epoch 50/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.0919e-04 - val_loss: 4.3268e-04\n",
            "Epoch 51/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0431e-04 - val_loss: 4.2798e-04\n",
            "Epoch 52/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0268e-04 - val_loss: 4.2715e-04\n",
            "Epoch 53/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.9994e-04 - val_loss: 4.2733e-04\n",
            "Epoch 54/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.9933e-04 - val_loss: 4.2488e-04\n",
            "Epoch 55/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.0052e-04 - val_loss: 4.3061e-04\n",
            "Epoch 56/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9570e-04 - val_loss: 4.2025e-04\n",
            "Epoch 57/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.9848e-04 - val_loss: 4.1997e-04\n",
            "Epoch 58/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.9310e-04 - val_loss: 4.3046e-04\n",
            "Epoch 59/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9320e-04 - val_loss: 4.2233e-04\n",
            "Epoch 60/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9026e-04 - val_loss: 4.2198e-04\n",
            "Epoch 61/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8971e-04 - val_loss: 4.1698e-04\n",
            "Epoch 62/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9087e-04 - val_loss: 4.1737e-04\n",
            "Epoch 63/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.9330e-04 - val_loss: 4.1301e-04\n",
            "Epoch 64/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8584e-04 - val_loss: 4.1741e-04\n",
            "Epoch 65/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8901e-04 - val_loss: 4.1762e-04\n",
            "Epoch 66/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9149e-04 - val_loss: 4.2012e-04\n",
            "Epoch 67/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8726e-04 - val_loss: 4.1735e-04\n",
            "Epoch 68/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.8299e-04 - val_loss: 4.1831e-04\n",
            "Epoch 69/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8153e-04 - val_loss: 4.1475e-04\n",
            "Epoch 70/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.8667e-04 - val_loss: 4.1198e-04\n",
            "Epoch 71/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8874e-04 - val_loss: 4.3226e-04\n",
            "Epoch 72/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9507e-04 - val_loss: 4.1144e-04\n",
            "Epoch 73/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7764e-04 - val_loss: 4.0459e-04\n",
            "Epoch 74/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.8407e-04 - val_loss: 4.1653e-04\n",
            "Epoch 75/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7877e-04 - val_loss: 4.0369e-04\n",
            "Epoch 76/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7886e-04 - val_loss: 4.0674e-04\n",
            "Epoch 77/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7487e-04 - val_loss: 4.1055e-04\n",
            "Epoch 78/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8237e-04 - val_loss: 4.0667e-04\n",
            "Epoch 79/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7486e-04 - val_loss: 4.0498e-04\n",
            "Epoch 80/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8409e-04 - val_loss: 4.2051e-04\n",
            "Epoch 81/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7900e-04 - val_loss: 4.0501e-04\n",
            "Epoch 82/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8684e-04 - val_loss: 4.0717e-04\n",
            "Epoch 83/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8083e-04 - val_loss: 4.0235e-04\n",
            "Epoch 84/150\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 3.8017e-04 - val_loss: 4.0832e-04\n",
            "Epoch 85/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8155e-04 - val_loss: 4.0590e-04\n",
            "Epoch 86/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7863e-04 - val_loss: 4.0824e-04\n",
            "Epoch 87/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7818e-04 - val_loss: 4.0126e-04\n",
            "Epoch 88/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7132e-04 - val_loss: 4.1931e-04\n",
            "Epoch 89/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7694e-04 - val_loss: 3.9981e-04\n",
            "Epoch 90/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7628e-04 - val_loss: 4.0484e-04\n",
            "Epoch 91/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7781e-04 - val_loss: 4.0910e-04\n",
            "Epoch 92/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7912e-04 - val_loss: 4.1141e-04\n",
            "Epoch 93/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7758e-04 - val_loss: 4.1018e-04\n",
            "Epoch 94/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6837e-04 - val_loss: 4.0361e-04\n",
            "Epoch 95/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7039e-04 - val_loss: 4.0218e-04\n",
            "Epoch 96/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7374e-04 - val_loss: 3.9761e-04\n",
            "Epoch 97/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6886e-04 - val_loss: 4.0817e-04\n",
            "Epoch 98/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7254e-04 - val_loss: 4.2940e-04\n",
            "Epoch 99/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7435e-04 - val_loss: 4.0406e-04\n",
            "Epoch 100/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6748e-04 - val_loss: 3.9689e-04\n",
            "Epoch 101/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7356e-04 - val_loss: 3.9810e-04\n",
            "Epoch 102/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7187e-04 - val_loss: 4.1299e-04\n",
            "Epoch 103/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6627e-04 - val_loss: 3.9499e-04\n",
            "Epoch 104/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6800e-04 - val_loss: 4.1062e-04\n",
            "Epoch 105/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7355e-04 - val_loss: 4.0522e-04\n",
            "Epoch 106/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7378e-04 - val_loss: 4.0301e-04\n",
            "Epoch 107/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6800e-04 - val_loss: 4.0206e-04\n",
            "Epoch 108/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6606e-04 - val_loss: 4.0435e-04\n",
            "Epoch 109/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7209e-04 - val_loss: 3.9505e-04\n",
            "Epoch 110/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6894e-04 - val_loss: 4.0135e-04\n",
            "Epoch 111/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.8131e-04 - val_loss: 4.0230e-04\n",
            "Epoch 112/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8139e-04 - val_loss: 4.1420e-04\n",
            "Epoch 113/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6800e-04 - val_loss: 4.0082e-04\n",
            "Epoch 114/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6997e-04 - val_loss: 4.1399e-04\n",
            "Epoch 115/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7193e-04 - val_loss: 4.4445e-04\n",
            "Epoch 116/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8472e-04 - val_loss: 4.4106e-04\n",
            "Epoch 117/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6570e-04 - val_loss: 3.9724e-04\n",
            "Epoch 118/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7348e-04 - val_loss: 4.1596e-04\n",
            "Epoch 119/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7143e-04 - val_loss: 3.9450e-04\n",
            "Epoch 120/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7469e-04 - val_loss: 4.3286e-04\n",
            "Epoch 121/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6660e-04 - val_loss: 3.9492e-04\n",
            "Epoch 122/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7835e-04 - val_loss: 4.1309e-04\n",
            "Epoch 123/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7225e-04 - val_loss: 3.9293e-04\n",
            "Epoch 124/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7126e-04 - val_loss: 3.9529e-04\n",
            "Epoch 125/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6054e-04 - val_loss: 3.9512e-04\n",
            "Epoch 126/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6942e-04 - val_loss: 3.9707e-04\n",
            "Epoch 127/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7928e-04 - val_loss: 3.9299e-04\n",
            "Epoch 128/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6373e-04 - val_loss: 3.9046e-04\n",
            "Epoch 129/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7970e-04 - val_loss: 4.2590e-04\n",
            "Epoch 130/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6575e-04 - val_loss: 4.1251e-04\n",
            "Epoch 131/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6972e-04 - val_loss: 4.0404e-04\n",
            "Epoch 132/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7422e-04 - val_loss: 4.8741e-04\n",
            "Epoch 133/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7756e-04 - val_loss: 4.1364e-04\n",
            "Epoch 134/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7863e-04 - val_loss: 4.0732e-04\n",
            "Epoch 135/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7232e-04 - val_loss: 4.1468e-04\n",
            "Epoch 136/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6596e-04 - val_loss: 3.9233e-04\n",
            "Epoch 137/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6778e-04 - val_loss: 3.9430e-04\n",
            "Epoch 138/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6354e-04 - val_loss: 4.1586e-04\n",
            "Epoch 139/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6067e-04 - val_loss: 4.1169e-04\n",
            "Epoch 140/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6138e-04 - val_loss: 3.8879e-04\n",
            "Epoch 141/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6523e-04 - val_loss: 4.0151e-04\n",
            "Epoch 142/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7400e-04 - val_loss: 3.9616e-04\n",
            "Epoch 143/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.7197e-04 - val_loss: 3.9107e-04\n",
            "Epoch 144/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6691e-04 - val_loss: 3.9376e-04\n",
            "Epoch 145/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5894e-04 - val_loss: 3.9268e-04\n",
            "Epoch 146/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6212e-04 - val_loss: 4.0279e-04\n",
            "Epoch 147/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7135e-04 - val_loss: 4.0472e-04\n",
            "Epoch 148/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6059e-04 - val_loss: 3.9701e-04\n",
            "Epoch 149/150\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6220e-04 - val_loss: 4.7593e-04\n",
            "Epoch 150/150\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7003e-04 - val_loss: 4.0351e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_train=np.random.uniform(-np.pi,np.pi,1000)\n",
        "y_train=(np.cos(x_train) + 1)/2\n",
        "\n",
        "x_test=np.random.uniform(-np.pi,np.pi,100)\n",
        "y_test=(np.cos(x_test) + 1)/2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(120, input_dim=1, activation='relu', use_bias=True))\n",
        "model.add(Dense(1, use_bias=True, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='Adam')\n",
        "\n",
        "model.fit(x_train,y_train,epochs=150,verbose=1,validation_data=(x_test, y_test))\n",
        "\n",
        "result = model.predict(x_test)\n",
        "\n",
        "y_predict = result[:,0]\n",
        "\n",
        "plt.scatter(x_test, y_test)\n",
        "plt.scatter(x_test, y_predict)\n",
        "plt.show()"
      ]
    }
  ]
}